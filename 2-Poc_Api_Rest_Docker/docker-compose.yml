version: "3.8"

services:
  
  # NGINX - Load balance / Proxy
  nginx-server:
      container_name: nginx-server
      restart: always
      image: "nginx:latest"
      ports:
        - "7000:7000"
      volumes:
        - ./nginx-server:/etc/nginx/conf.d
      depends_on:
        - django-server
      networks:
        - web-network
    
  # RabbitMQ - Filas
  broker-server:
    image: rabbitmq:3-management
    container_name: broker-server
    restart: always
    environment:
      - RABBITMQ_DEFAULT_USER=fake
      - RABBITMQ_DEFAULT_PASS=fake123       
    ports:
      - "5672:5672"
      - "15672:15672"
      - "25676:25676"
    networks:
      - server-events
  
  # Postgres - System Database 
  postgres-server:
    image: postgres:alpine3.18
    container_name: postgres-server
    restart: always
    healthcheck:
      test: [ "CMD", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_DB=simpleDB
      - POSTGRES_PASSWORD=fake123
    volumes:
      - './volumes/postgres-data:/var/lib/postgresql/data'
    networks:
      - server-db-postgres
    ports:
        - "6666:5432"

  # Django - System Admin / API REST / Celery
  django-server: &common-settings
    build:
      context: django-server
      dockerfile: Dockerfile
    container_name: django-server
    command: gunicorn --timeout=3600 --bind=0.0.0.0:5005 core.wsgi:application
    depends_on:
      - broker-server
      - postgres-server
    env_file:
      - .envFile
    restart: always
    volumes:
      - ./django-server:/app
      - ./volumes/logs:/app/logs/
      - ./volumes/ftp:/app/media/
    networks:
      - server-db-postgres
      - web-network
      - server-events
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 2048M
        reservations:
          cpus: '0.25'
          memory: 512M

  django-server-task:
    <<: *common-settings
    container_name: django-server-task
    command: celery -A core.settings worker -l info

  # Scripts para Jobs de Scrapping recebidos na Fila Scrapping
  jobs-server:
    container_name: jobs-server
    build:
      context: lambda-server
      dockerfile: Dockerfile
    restart: always
    command: ["python", "consumer-scrapping.py"]
    depends_on:
      - django-server
      - broker-server
    volumes:
      - ./lambda-server/src/:/jobs/
      - ./volumes/ftp/:/jobs/ftp/
      - ./volumes/logs:/jobs/logs/
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - server-events
      - server-db-postgres

networks:
  server-db-postgres:
    driver: bridge
  web-network:
    driver: bridge
  server-events:
    driver: bridge
