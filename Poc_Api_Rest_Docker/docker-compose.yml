
version: "3.8"

services:

  # RabbitMQ - Filas
  broker-server:
    image: rabbitmq:3-management
    container_name: broker-server
    restart: always
    environment:
      - RABBITMQ_DEFAULT_USER=fake
      - RABBITMQ_DEFAULT_PASS=fake123
    volumes:
      - ./volumes/rabbitmq:/var/lib/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
      - "25676:25676"
    networks:
      - server-hosts
  
  # Postgres - System Database 
  postgres-server:
    image: postgres:alpine3.18
    container_name: postgres-server
    restart: always
    healthcheck:
      test: [ "CMD", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_DB=simpleDB
      - POSTGRES_PASSWORD=fake123
    volumes:
      - './volumes/postgres:/var/lib/postgresql/data'
    ports:
      - 5432:5432
    networks:
      - server-hosts
  
 # Django - System Admin / API REST 
  django-server:
    build:
      context: django-server
      dockerfile: Dockerfile
    container_name: django-server
    command: gunicorn --timeout=3600 --bind=0.0.0.0:5005 core.wsgi:application
    depends_on:
      - postgres-server
    environment:
      - PG_HOST=postgres-server
      - PG_PORT=5432
      - PG_DATABASE=simpleDB
      - PG_PASSWORD=fake123
    restart: always
    ports:
      - "5005:5005"
    volumes:
      - ./django-server:/app
      - ./volumes/logs:/app/logs/
      - ./volumes/ftp:/app/media/

    networks:
      - server-hosts
      - web_network

  nginx-server:
      container_name: nginx-server
      restart: always
      image: "nginx:latest"
      ports:
        - "7000:7000"
      volumes:
        - ./nginx-server:/etc/nginx/conf.d
      networks:
        - web_network
      depends_on:
        - django-server

# Celery - System Task Manager
  beat-scheduler:
    build:
      context: django-server
      dockerfile: Dockerfile
    command: celery -A core beat --loglevel=INFO --logfile=/api/media/logs/celery-beat.log --scheduler django_celery_beat.schedulers:DatabaseScheduler
    depends_on:
      - postgres-server
      - broker-server
    restart: always
    volumes:
      - ./volumes/ftp:/api/media/ftp/
      - ./volumes/logs:/api/media/logs/
    networks:
      - server-hosts

# Celery - System Task Worker
  tasks-workers:
    build:
      context: django-server
      dockerfile: Dockerfile
    command: celery -A core worker --loglevel=INFO --logfile=/api/media/logs/celery-worker.log
    depends_on:
      - postgres-server
      - broker-server
    restart: always
    volumes:
      - ./volumes/ftp:/api/media/ftp/
      - ./volumes/logs:/api/media/logs/
    networks:
      - server-hosts

  flask-app:
    container_name: flask-app
    build:
      context: flask-server/
      dockerfile: Dockerfile
    restart: always
    ports: 
      - "5000:5000"
    environment: 
      - MYSQL_HOST = mysql
    volumes: 
      - ./flask-server/api:/api # Compartilamento de volume para o diretório src
    deploy:
      resources:
        limits:
          cpus: '0.50'  # Limite de CPU para 50% de um núcleo
          memory: 1024M  # Limite de memória para 1024 MB
        reservations:
          cpus: '0.25'  # Reserva mínima de CPU para 25% de um núcleo
          memory: 512M  # Reserva mínima de memória para 256 MB
    networks:
      - server-hosts
      - web_network

networks:
  server-hosts:
    driver: bridge
  web_network:
    driver: bridge